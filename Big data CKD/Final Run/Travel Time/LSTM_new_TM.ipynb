{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM_new_TM.ipynb","provenance":[],"authorship_tag":"ABX9TyMUK+N/UuzWdQ5kwRdZ6Ppz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","class cust():\n","    \n","    def __init__(self, dat):\n","        self.dat = dat\n","\n","        \n","    def xy(self, x_dummies_list, X_list, y_list):\n","        \n","        X = self.dat[X_list]\n","        y = self.dat[y_list]\n","        \n","        # One hot encoding the pg column\n","        X = pd.get_dummies(X, columns = x_dummies_list, drop_first = True)\n","        # C_cols should be after get_dummies so we get ALL columns\n","        x_cols = X.columns\n","        # Convert the two into value arrays\n","        X = X.values\n","        y = y.values\n","        # We need y as a 1D array\n","        y = np.ravel(y)\n","\n","        return X,y,x_cols\n","    \n","    \n","    # Same as xy except returns a dataframe instead of a float64 np array\n","    def xy_df(self, x_dummies_list, X_list, y_list):\n","        \n","        X = self.dat[X_list]\n","        y = self.dat[y_list]\n","        \n","        # One hot encoding the pg column\n","        X = pd.get_dummies(X, columns = x_dummies_list, drop_first = True)\n","        # C_cols should be after get_dummies so we get ALL columns\n","        x_cols = X.columns\n","        # We need y as a 1D array\n","        y = np.ravel(y)\n","\n","        return X,y,x_cols    \n","    \n","    \n","    def clean_data(self):\n","        self.dat.replace([np.inf, -np.inf], np.nan) # Replace inf\n","        self.dat = self.dat.dropna(axis=0, how = 'any') # Drop NA's on the rows axis\n","        # I kept getting a value error and this was the only thing that seemed to fix it\n","        self.dat = self.dat[~self.dat.isin([np.nan, np.inf, -np.inf]).any(1)]\n","        return self.dat\n","    \n","    \n","    def outlier_removal(self,var):\n","        IQR = self.dat[var].describe()['75%'] - self.dat[var].describe()['25%']\n","        min_val = self.dat[var].describe()['25%'] - (IQR * 1.5)\n","        max_val = self.dat[var].describe()['75%'] + (IQR * 1.5)\n","        \n","        self.dat = self.dat[(self.dat[var] > min_val) & (self.dat[var] < max_val)]\n","        plt.boxplot(self.dat[var])\n","        return self.dat\n","         \n","    @staticmethod\n","    def comparison_df(y_pred, y_test):\n","        # Dataframe of pred and actual y\n","        comparison_df = pd.DataFrame({'y_pred':y_pred, 'y_test':y_test})\n","        comparison_df['abs_difference'] = abs( comparison_df['y_pred'] - comparison_df['y_test'] )\n","        comparison_df['real_difference'] = comparison_df['y_pred'] - comparison_df['y_test'] \n","        print(comparison_df.describe())\n","        # Show all sums\n","        print(comparison_df.sum())\n","        # Show average difference\n","        print (\"Average Difference: \", comparison_df.sum()[2] / len(comparison_df))\n","        \n","        return comparison_df"],"metadata":{"id":"w-fNO-aZ-9Au","executionInfo":{"status":"ok","timestamp":1639267953565,"user_tz":300,"elapsed":198,"user":{"displayName":"Shamima Akter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPJvbs09XMJHGonY2iTwD9S7s6hYvWVwxn5XfX=s64","userId":"07570024981421945247"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Time Series\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def create_series(df, xcol, datecol):\n","    # Create a dataframe with the features and the date time as the index\n","    features_considered = [xcol]\n","    features = df[features_considered]\n","    features.index = df[datecol]\n","    features.head()\n","    features.plot(subplots=True)\n","    return features\n","\n","\n","# X is the series to test\n","# log_x asks whether to log X prior to testing or not\n","def stationarity_test(X, log_x = \"Y\", return_p = False, print_res = True):\n","    \n","    # If X isn't logged, we need to log it for better results\n","    if log_x == \"Y\":\n","        X = np.log(X[X>0])\n","    \n","    # Once we have the series as needed we can do the ADF test\n","    from statsmodels.tsa.stattools import adfuller\n","    dickey_fuller = adfuller(X)\n","    \n","    if print_res:\n","    # If ADF statistic is < our 1% critical value (sig level) we can conclude it's not a fluke (ie low P val / reject H(0))\n","        print('ADF Stat is: {}.'.format(dickey_fuller[0]))\n","        # A lower p val means we can reject the H(0) that our data is NOT stationary\n","        print('P Val is: {}.'.format(dickey_fuller[1]))\n","        print('Critical Values (Significance Levels): ')\n","        for key,val in dickey_fuller[4].items():\n","            print(key,\":\",round(val,3))\n","            \n","    if return_p:\n","        return dickey_fuller[1]\n","    \n","# Differencing the data    \n","def difference(X):\n","    diff = X.diff()\n","    plt.plot(diff)\n","    plt.show()\n","    return diff"],"metadata":{"id":"1_SuEmea9ayj","executionInfo":{"status":"ok","timestamp":1639268075314,"user_tz":300,"elapsed":155,"user":{"displayName":"Shamima Akter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPJvbs09XMJHGonY2iTwD9S7s6hYvWVwxn5XfX=s64","userId":"07570024981421945247"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["import time_series \n","import numpy as np\n","from numpy import newaxis\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","class Data_Prep:\n","    \n","    def __init__(self, dataset):\n","        self.dataset = dataset\n","        \n","    \n","    def preprocess_rnn(self, date_colname, numeric_colname, pred_set_timesteps):\n","        features = (time_series.create_series(self.dataset, numeric_colname, date_colname)).sort_index()\n","        rnn_df = features.groupby(features.index).sum()\n","        \n","        # Filter out 'n' timesteps for prediction purposes\n","        timestep_idx = len(rnn_df)-pred_set_timesteps\n","        validation_df = rnn_df.iloc[timestep_idx:]\n","        rnn_df = rnn_df.iloc[1:timestep_idx,]\n","        \n","        # Dickey Fuller Test\n","        print(\"Summary Statistics - ADF Test For Stationarity\\n\")\n","        if time_series.stationarity_test(X = rnn_df[numeric_colname], return_p=True, print_res = False) > 0.05:\n","            print(\"P Value is high. Consider Differencing: \" + str(time_series.stationarity_test(X = rnn_df[numeric_colname], return_p = True, print_res = False)))\n","        else:\n","            time_series.stationarity_test(X = rnn_df[numeric_colname])\n","        \n","        # Sorting\n","        rnn_df = rnn_df.sort_index(ascending = True)\n","        rnn_df = rnn_df.reset_index()\n","        \n","        return rnn_df, validation_df\n","    \n","    \n","class Series_Prep:\n","    \n","    def __init__(self, rnn_df, numeric_colname):\n","        self.rnn_df = rnn_df\n","        self.numeric_colname = numeric_colname\n","\n","    def make_window(self, sequence_length, train_test_split, return_original_x = True):\n","        \n","        # Create the initial results df with a look_back of 60 days\n","        result = []\n","        \n","        # 3D Array\n","        for index in range(len(self.rnn_df) - sequence_length):\n","            result.append(self.rnn_df[self.numeric_colname][index: index + sequence_length])  \n","        \n","        # Getting the initial train_test split for our min/max val scalar\n","        train_test_split = 0.9\n","        row = int(round(train_test_split * np.array(result).shape[0]))\n","        train = np.array(result)[:row, :]\n","        X_train = train[:, :-1]\n","        \n","        # Manual MinMax Scaler\n","        X_min = X_train.min()\n","        X_max = X_train.max()\n","        \n","        # keep the originals in case\n","        X_min_orig = X_train.min()\n","        X_max_orig = X_train.max()\n","        \n","        # Minmax scaler and a reverse method\n","        def minmax(X):\n","            return (X-X_min) / (X_max - X_min)\n","        \n","        def reverse_minmax(X):\n","            return X * (X_max-X_min) + X_min\n","        \n","        # Method for Scaler for each window in our 3D array\n","        def minmax_windows(window_data):\n","            normalised_data = []\n","            for window in window_data:\n","                window.index = range(sequence_length)\n","                normalised_window = [((minmax(p))) for p in window]\n","                normalised_data.append(normalised_window)\n","            return normalised_data\n","        \n","        # minmax the windows\n","        result = minmax_windows(result)\n","        # Convert to 2D array\n","        result = np.array(result)\n","        if return_original_x:\n","            return result, X_min_orig, X_max_orig\n","        else:\n","            return result\n","        \n","    @staticmethod\n","    def reshape_window(window, train_test_split = 0.8):\n","        # Train/test for real this time\n","        row = round(train_test_split * window.shape[0])\n","        train = window[:row, :]\n","        \n","        # Get the sets\n","        X_train = train[:, :-1]\n","        y_train = train[:, -1]\n","        X_test = window[row:, :-1]\n","        y_test = window[row:, -1]\n","        \n","        # Reshape for LSTM\n","        X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n","        X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n","        y_train = np.reshape(y_train, (-1,1))\n","        y_test = np.reshape(y_test, (-1,1))\n","        \n","        return X_train, X_test, y_train, y_test\n","    \n","    \n","class Predict_Future:\n","\n","\n","    def __init__(self, X_test, validation_df, lstm_model):\n","        self.X_test = X_test\n","        self.validation_df = validation_df\n","        self.lstm_model = lstm_model\n","        \n","    def predicted_vs_actual(self, X_min, X_max, numeric_colname):\n","        \n","        curr_frame = self.X_test[len(self.X_test)-1]\n","        future = []\n","        \n","        for i in range(len(self.validation_df)):\n","              # append the prediction to our empty future list\n","             future.append(self.lstm_model.predict(curr_frame[newaxis,:,:])[0,0])\n","              # insert our predicted point to our current frame\n","             curr_frame = np.insert(curr_frame, len(self.X_test[0]), future[-1], axis=0)\n","              # push the frame up one to make it progress into the future\n","             curr_frame = curr_frame[1:]\n","        \n","        def reverse_minmax(X, X_max = X_max, X_min = X_min):\n","            return X * (X_max-X_min) + X_min\n","\n","        # Plot \n","        reverse_curr_frame = pd.DataFrame({numeric_colname: [reverse_minmax(x) for x in self.X_test[len(self.X_test)-1]],\n","                                           \"historical_flag\":1})\n","        reverse_future = pd.DataFrame({numeric_colname: [reverse_minmax(x) for x in future],\n","                                           \"historical_flag\":0})\n","        \n","        # Change the indicies! Only for FUTURE predictions\n","        # reverse_future.index += len(reverse_curr_frame)\n","        \n","        print(\"See Plot for predicted vs. actuals\")\n","        plt.plot(reverse_curr_frame[numeric_colname])\n","        plt.plot(reverse_future[numeric_colname])\n","        plt.title(\"Predicted Points Vs. Actuals (Validation)\")\n","        plt.show()\n","        \n","        # Check accuracy vs. actuals\n","        comparison_df = pd.DataFrame({\"Validation\": self.validation_df[numeric_colname],\n","                                      \"Predicted\": [reverse_minmax(x) for x in future]})\n","        print(\"Validation Vs. Predicted\")\n","        print(comparison_df.sum())\n","        \n","        \n","    def predict_future(self, X_min, X_max, numeric_colname, timesteps_to_predict, return_future = True):\n","    \n","        curr_frame = self.X_test[len(self.X_test)-1]\n","        future = []\n","        \n","        for i in range(timesteps_to_predict):\n","              # append the prediction to our empty future list\n","             future.append(self.lstm_model.predict(curr_frame[newaxis,:,:])[0,0])\n","              # insert our predicted point to our current frame\n","             curr_frame = np.insert(curr_frame, len(self.X_test[0]), future[-1], axis=0)\n","              # push the frame up one to make it progress into the future\n","             curr_frame = curr_frame[1:]\n","        \n","        def reverse_minmax(X, X_max = X_max, X_min = X_min):\n","            return X * (X_max-X_min) + X_min\n","\n","        # Reverse the original frame and the future frame\n","        reverse_curr_frame = pd.DataFrame({numeric_colname: [reverse_minmax(x) for x in self.X_test[len(self.X_test)-1]],\n","                                           \"historical_flag\":1})\n","        reverse_future = pd.DataFrame({numeric_colname: [reverse_minmax(x) for x in future],\n","                                           \"historical_flag\":0})\n","        \n","        # Change the indicies to show prediction next to the actuals in orange\n","        reverse_future.index += len(reverse_curr_frame)\n","        \n","        print(\"See Plot for Future Predictions\")\n","        plt.plot(reverse_curr_frame[numeric_colname])\n","        plt.plot(reverse_future[numeric_colname])\n","        plt.title(\"Predicted Future of \"+ str(timesteps_to_predict) + \" days\")\n","        plt.show()\n","        \n","        if return_future:\n","            return reverse_future\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"qRwd3OwE-Rnd","executionInfo":{"status":"error","timestamp":1639276818145,"user_tz":300,"elapsed":659,"user":{"displayName":"Shamima Akter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPJvbs09XMJHGonY2iTwD9S7s6hYvWVwxn5XfX=s64","userId":"07570024981421945247"}},"outputId":"0b721a7b-2842-47d8-870b-c07de7bfa27f"},"execution_count":19,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-af929a83fb9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtime_series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnewaxis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'time_series'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["#Importation\n","import os\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import LSTM_Prep\n","\n","# Data\n","dat = pd.read_csv('sample_data/Forex.csv')\n","\n","split = 0.8\n","sequence_length = 60\n","\n","data_prep = LSTM_Prep.Data_Prep(dataset = dat)\n","rnn_df, validation_df = data_prep.preprocess_rnn(date_colname = 'date', numeric_colname = 'perc', pred_set_timesteps = 60)\n","\n","\n","series_prep = LSTM_Prep.Series_Prep(rnn_df =  rnn_df, numeric_colname = 'perc')\n","window, X_min, X_max = series_prep.make_window(sequence_length = sequence_length, \n","                                               train_test_split = split, \n","                                               return_original_x = True)\n","\n","X_train, X_test, y_train, y_test = series_prep.reshape_window(window, train_test_split = split)\n","\n","\n","# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #\n","#                 Building the LSTM\n","# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense\n","from keras.callbacks import ReduceLROnPlateau #Learning rate scheduler for when we reach plateaus\n","rlrop = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=100)\n","\n","# Reset model if we want to re-train with different splits\n","def reset_weights(model):\n","    import keras.backend as K\n","    session = K.get_session()\n","    for layer in model.layers: \n","        if hasattr(layer, 'kernel_initializer'): \n","            layer.kernel.initializer.run(session=session)\n","        if hasattr(layer, 'bias_initializer'):\n","            layer.bias.initializer.run(session=session)  \n","\n","\n","# Epochs and validation split\n","EPOCHS = 201\n","validation = 0.05\n","\n","# Instantiate the model\n","model = Sequential()\n","\n","# Add the first layer.... the input shape is (Sample, seq_len-1, 1)\n","model.add(LSTM(\n","        input_shape = (sequence_length-1, 1), return_sequences = True,\n","        units = 100))\n","\n","# Add the second layer.... the input shape is (Sample, seq_len-1, 1)\n","model.add(LSTM(\n","        input_shape = (sequence_length-1, 1), \n","        units = 100))\n","\n","# Add the output layer, simply one unit\n","model.add(Dense(\n","        units = 1,\n","        activation = 'sigmoid'))\n","\n","model.compile(loss = 'mse', optimizer = 'adam')\n","\n","\n","# History object for plotting our model loss by epoch\n","history = model.fit(X_train, y_train, epochs = EPOCHS, validation_split = validation,\n","          callbacks = [rlrop])\n","# Loss History\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model Loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Test'], loc='upper left')\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"aMRr_VW-_hYP","executionInfo":{"status":"error","timestamp":1639268124561,"user_tz":300,"elapsed":169,"user":{"displayName":"Shamima Akter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPJvbs09XMJHGonY2iTwD9S7s6hYvWVwxn5XfX=s64","userId":"07570024981421945247"}},"outputId":"a83ec931-f6ff-4f5c-9a48-19daeb6b3720"},"execution_count":18,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-a92326d8cb07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mLSTM_Prep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'LSTM_Prep'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]}]}