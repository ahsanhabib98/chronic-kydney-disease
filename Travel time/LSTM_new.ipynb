{"cells":[{"cell_type":"code","execution_count":7,"metadata":{"id":"WD6hJMwDRgNe","executionInfo":{"status":"ok","timestamp":1639323647479,"user_tz":300,"elapsed":132,"user":{"displayName":"Shamima Akter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPJvbs09XMJHGonY2iTwD9S7s6hYvWVwxn5XfX=s64","userId":"07570024981421945247"}}},"outputs":[],"source":["                 import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"AcV25rj_6UC3","executionInfo":{"status":"ok","timestamp":1639323648705,"user_tz":300,"elapsed":135,"user":{"displayName":"Shamima Akter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPJvbs09XMJHGonY2iTwD9S7s6hYvWVwxn5XfX=s64","userId":"07570024981421945247"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"71yEtUvz6o16","executionInfo":{"status":"ok","timestamp":1639323650445,"user_tz":300,"elapsed":120,"user":{"displayName":"Shamima Akter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPJvbs09XMJHGonY2iTwD9S7s6hYvWVwxn5XfX=s64","userId":"07570024981421945247"}}},"outputs":[],"source":["dataset = pd.read_csv('sample_data/Test data.csv')"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":118,"status":"ok","timestamp":1639323652167,"user":{"displayName":"Shamima Akter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPJvbs09XMJHGonY2iTwD9S7s6hYvWVwxn5XfX=s64","userId":"07570024981421945247"},"user_tz":300},"id":"whD4_3qF6vom","outputId":"199cc263-ca9a-421e-bc22-dec59c906b84"},"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>T(t-15)</th>\n","      <th>T(t-30)</th>\n","      <th>T(t-45)</th>\n","      <th>T(t-60)</th>\n","      <th>T((t-15)-(t-30))</th>\n","      <th>T((t-30)-(t-45))</th>\n","      <th>T((t-45)-(t-60))</th>\n","      <th>Time of day</th>\n","      <th>Day</th>\n","      <th>Week</th>\n","      <th>Weekday</th>\n","      <th>Month</th>\n","      <th>Weather</th>\n","      <th>Tt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5658</th>\n","      <td>6.67</td>\n","      <td>6.76</td>\n","      <td>6.93</td>\n","      <td>6.54</td>\n","      <td>-0.09</td>\n","      <td>-0.17</td>\n","      <td>0.39</td>\n","      <td>91</td>\n","      <td>59</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>6.67</td>\n","    </tr>\n","    <tr>\n","      <th>5659</th>\n","      <td>6.63</td>\n","      <td>6.67</td>\n","      <td>6.76</td>\n","      <td>6.93</td>\n","      <td>-0.04</td>\n","      <td>-0.09</td>\n","      <td>-0.17</td>\n","      <td>92</td>\n","      <td>59</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>6.63</td>\n","    </tr>\n","    <tr>\n","      <th>5660</th>\n","      <td>6.79</td>\n","      <td>6.63</td>\n","      <td>6.67</td>\n","      <td>6.76</td>\n","      <td>0.16</td>\n","      <td>-0.04</td>\n","      <td>-0.09</td>\n","      <td>93</td>\n","      <td>59</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>6.79</td>\n","    </tr>\n","    <tr>\n","      <th>5661</th>\n","      <td>55.76</td>\n","      <td>6.79</td>\n","      <td>6.63</td>\n","      <td>6.67</td>\n","      <td>48.97</td>\n","      <td>0.16</td>\n","      <td>-0.04</td>\n","      <td>94</td>\n","      <td>59</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>55.76</td>\n","    </tr>\n","    <tr>\n","      <th>5662</th>\n","      <td>56.54</td>\n","      <td>55.76</td>\n","      <td>6.79</td>\n","      <td>6.63</td>\n","      <td>0.78</td>\n","      <td>48.97</td>\n","      <td>0.16</td>\n","      <td>95</td>\n","      <td>59</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>56.54</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      T(t-15)  T(t-30)  T(t-45)  T(t-60)  ...  Weekday  Month  Weather     Tt\n","5658     6.67     6.76     6.93     6.54  ...        5      2        1   6.67\n","5659     6.63     6.67     6.76     6.93  ...        5      2        2   6.63\n","5660     6.79     6.63     6.67     6.76  ...        5      2        3   6.79\n","5661    55.76     6.79     6.63     6.67  ...        5      2        1  55.76\n","5662    56.54    55.76     6.79     6.63  ...        5      2        2  56.54\n","\n","[5 rows x 14 columns]"]},"metadata":{},"execution_count":10}],"source":["dataset.tail()"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":135,"status":"ok","timestamp":1639323747826,"user":{"displayName":"Shamima Akter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPJvbs09XMJHGonY2iTwD9S7s6hYvWVwxn5XfX=s64","userId":"07570024981421945247"},"user_tz":300},"id":"Uz4ySu4z6yef","outputId":"61f8b24b-5dc9-442d-a39b-e187c2118898"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["T(t-15)             0\n","T(t-30)             0\n","T(t-45)             0\n","T(t-60)             0\n","T((t-15)-(t-30))    0\n","T((t-30)-(t-45))    0\n","T((t-45)-(t-60))    0\n","Time of day         0\n","Day                 0\n","Week                0\n","Weekday             0\n","Month               0\n","Weather             0\n","Tt                  0\n","dtype: int64"]},"metadata":{},"execution_count":11}],"source":["dataset.isnull().sum()"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":118,"status":"ok","timestamp":1639323750036,"user":{"displayName":"Shamima Akter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPJvbs09XMJHGonY2iTwD9S7s6hYvWVwxn5XfX=s64","userId":"07570024981421945247"},"user_tz":300},"id":"9ZfTFTZQEZwc","outputId":"cb9025d4-38b1-4c80-809c-97ebf986542e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5663, 14)"]},"metadata":{},"execution_count":12}],"source":["dataset.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1639317621312,"user":{"displayName":"Manik Ahmed","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11247937406887651800"},"user_tz":300},"id":"4Sp3ng0dFcl5","outputId":"8587a8a7-fc43-4da9-b3fc-c2043527eef7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["93.0"]},"metadata":{},"execution_count":7}],"source":["#dataset.loc[188]['Time of day']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1639317621313,"user":{"displayName":"Manik Ahmed","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11247937406887651800"},"user_tz":300},"id":"aSqqqrrEGiDs","outputId":"50e4adc2-9e16-4313-bf09-61353425b995"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":8}],"source":["# num = 97\n","# num//96"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1639317621313,"user":{"displayName":"Manik Ahmed","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11247937406887651800"},"user_tz":300},"id":"NT3-qToCCEek","outputId":"1ae949c2-a678-4af9-c31d-5f4246acd2fe"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["5663"]},"metadata":{},"execution_count":9}],"source":["#len(dataset['Time of day'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zs61OeYyOGQc"},"outputs":[],"source":["# num = 97\n","# for pos in range(189, len(dataset['Time of day'])):\n","#   if num%96 == 0:\n","#     dataset['Time of day'][pos] = 96\n","#   else:\n","#     dataset['Time of day'][pos] = num%96\n","#   num += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RBTlWI9QJ88-"},"outputs":[],"source":["# # Filling missing numeric data in the dataset with mean\n","# for i in ['T(t-15)','T(t-30)','T(t-45)','T(t-60)','Tt']:\n","#     dataset[i].fillna(dataset[i].mean(),inplace=True)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":151,"status":"ok","timestamp":1639323781317,"user":{"displayName":"Shamima Akter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPJvbs09XMJHGonY2iTwD9S7s6hYvWVwxn5XfX=s64","userId":"07570024981421945247"},"user_tz":300},"id":"pisf2mQeKUXU","outputId":"7342f57e-93ec-4e67-955e-d0133b56d122"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["T(t-15)             0\n","T(t-30)             0\n","T(t-45)             0\n","T(t-60)             0\n","T((t-15)-(t-30))    0\n","T((t-30)-(t-45))    0\n","T((t-45)-(t-60))    0\n","Time of day         0\n","Day                 0\n","Week                0\n","Weekday             0\n","Month               0\n","Weather             0\n","Tt                  0\n","dtype: int64"]},"metadata":{},"execution_count":13}],"source":["dataset.isnull().sum()"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"I2WRQfRSKl6a","executionInfo":{"status":"ok","timestamp":1639323783608,"user_tz":300,"elapsed":142,"user":{"displayName":"Shamima Akter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPJvbs09XMJHGonY2iTwD9S7s6hYvWVwxn5XfX=s64","userId":"07570024981421945247"}}},"outputs":[],"source":["# Data preprocessing\n","X = dataset.iloc[:,:-1].values\n","y = dataset.iloc[:,-1].values"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"WvulmcAhNFvY","executionInfo":{"status":"ok","timestamp":1639324400872,"user_tz":300,"elapsed":192,"user":{"displayName":"Shamima Akter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPJvbs09XMJHGonY2iTwD9S7s6hYvWVwxn5XfX=s64","userId":"07570024981421945247"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split    \n","from sklearn.preprocessing import MinMaxScaler\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n","\n","scaler = MinMaxScaler()\n","\n","X_train = scaler.fit_transform(X_train)\n","X_test  = scaler.transform(X_test)"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"c8UisGHgNOqW","executionInfo":{"status":"ok","timestamp":1639324403317,"user_tz":300,"elapsed":124,"user":{"displayName":"Shamima Akter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPJvbs09XMJHGonY2iTwD9S7s6hYvWVwxn5XfX=s64","userId":"07570024981421945247"}}},"outputs":[],"source":["from keras.models import Sequential\n","from tensorflow import keras\n","from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n","#from keras.optimizers import SGD\n","import math\n","from sklearn.metrics import mean_squared_error"]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing import sequence\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense,Flatten, Embedding, Dropout, Activation, Reshape"],"metadata":{"id":"PvYal4YYWmfj","executionInfo":{"status":"ok","timestamp":1639324481791,"user_tz":300,"elapsed":139,"user":{"displayName":"Shamima Akter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPJvbs09XMJHGonY2iTwD9S7s6hYvWVwxn5XfX=s64","userId":"07570024981421945247"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["from keras.layers.convolutional import Conv1D\n","from keras.layers.convolutional import MaxPooling1D\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import load_model\n","\n","def evaluate_model_CNN(X_train, X_val, y_train, y_val):\n","  #model = ANN\n","  timesteps=125\n","  dims=4\n","  model=Sequential()\n","#   model.add(LSTM(24,\n","#   dropout=0.2,return_sequences=True,\n","#   activation='tanh', recurrent_activation='tanh',recurrent_dropout=0.2,input_shape=(1,X_train.shape[2])))\n","#   model.add(LSTM(12, \n","#   activation='tanh', recurrent_activation='tanh',\n","#   dropout=0.2,recurrent_dropout=0.2))\n","  model.add(LSTM(64,activation='relu', input_shape=(X_train.shape[1],1)))\n","  #model.add(Dropout(0.5))\n","  #model.add(LSTM(20,return_sequences=False))\n","  #model.add(Dropout(0.5))\n","  model.add(Dense(1))\n","  #model.compile(loss='mse', optimizer='adam')\n","  #model.fit(X_train,y_train,epochs=100,validation_data=(X_test, y_test))\n","  model.add(keras.layers.Dense (256,input_shape=(X_train.shape[1],),activation='relu')) #input layer\n","  #model.add(keras.layers.Dense (128,activation='relu')) #hidden\n","  model.add(keras.layers.Dense (128,activation='relu')) #hidden\n","  model.add(keras.layers.Dense (64,activation='relu')) #hidden\n","  #model.add(keras.layers.Dense (64,activation='relu')) #hidden\n","  model.add(keras.layers.Dense (32,activation='relu')) #hidden\n","  model.add(keras.layers.Dense (16,activation='relu')) #hidden\n","  model.add(keras.layers.Dense (1)) #output\n","  #model.add(keras.layers.Dense (256,activation='relu')) #input layer\n","  # model.add(Dropout(0.2))\n","  # model.add(keras.layers.Dense (128,activation='relu')) #input layer\n","  # model.add(Dropout(0.2))\n","  # model.add(keras.layers.Dense (64,activation='relu')) #hidden\n","  # model.add(Dropout(0.3))\n","  # model.add(keras.layers.Dense (32,activation='relu')) #hidden\n","  # model.add(Dropout(0.3))\n","  # model.add(keras.layers.Dense (16,activation='relu')) #hidden\n","  # model.add(Dropout(0.3))\n","  # model.add(keras.layers.Dense (1,activation='softmax')) #output\n","  epochs = 400\n","  batch_size = 64\n","  model.compile(loss='mape', optimizer='adam')\n","  history = model.fit(X_train, y_train, validation_data = (X_val,y_val), epochs=300,batch_size=128,verbose=1)\n","  return history, model"],"metadata":{"id":"Ly6vbeXnU51r","executionInfo":{"status":"ok","timestamp":1639325110114,"user_tz":300,"elapsed":178,"user":{"displayName":"Shamima Akter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPJvbs09XMJHGonY2iTwD9S7s6hYvWVwxn5XfX=s64","userId":"07570024981421945247"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["n_folds = 1\n","cv_scores, model_history = list(), list()\n","#for _ in range(n_folds):  \n","  # split data\n","  # x_train, x_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state = np.random.randint(1,1000, 1)[0])\n","  # evaluate model\n","  # print(X_train.shape)\n","  # print(y_train.shape)\n","  # print(X_test.shape)\n","  # print(y_test.shape)\n","model = tf.keras.Sequential()\n","history, model= evaluate_model_CNN(X_train, X_test, y_train, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wP-01vjhWebT","executionInfo":{"status":"ok","timestamp":1639325346772,"user_tz":300,"elapsed":231300,"user":{"displayName":"Shamima Akter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPJvbs09XMJHGonY2iTwD9S7s6hYvWVwxn5XfX=s64","userId":"07570024981421945247"}},"outputId":"7e0e2687-97bb-405d-85dd-ae74f5d70bef"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/300\n","36/36 [==============================] - 3s 27ms/step - loss: 94.1215 - val_loss: 67.7113\n","Epoch 2/300\n","36/36 [==============================] - 1s 20ms/step - loss: 69.3572 - val_loss: 65.7570\n","Epoch 3/300\n","36/36 [==============================] - 1s 20ms/step - loss: 60.3941 - val_loss: 51.7628\n","Epoch 4/300\n","36/36 [==============================] - 1s 21ms/step - loss: 51.1143 - val_loss: 58.5866\n","Epoch 5/300\n","36/36 [==============================] - 1s 20ms/step - loss: 46.1352 - val_loss: 42.1604\n","Epoch 6/300\n","36/36 [==============================] - 1s 20ms/step - loss: 41.4772 - val_loss: 35.9885\n","Epoch 7/300\n","36/36 [==============================] - 1s 20ms/step - loss: 35.3197 - val_loss: 31.4034\n","Epoch 8/300\n","36/36 [==============================] - 1s 21ms/step - loss: 27.8448 - val_loss: 20.6935\n","Epoch 9/300\n","36/36 [==============================] - 1s 21ms/step - loss: 19.7235 - val_loss: 14.6747\n","Epoch 10/300\n","36/36 [==============================] - 1s 20ms/step - loss: 15.0490 - val_loss: 11.1880\n","Epoch 11/300\n","36/36 [==============================] - 1s 20ms/step - loss: 12.3577 - val_loss: 12.0340\n","Epoch 12/300\n","36/36 [==============================] - 1s 20ms/step - loss: 12.4597 - val_loss: 9.6646\n","Epoch 13/300\n","36/36 [==============================] - 1s 20ms/step - loss: 10.1854 - val_loss: 11.8905\n","Epoch 14/300\n","36/36 [==============================] - 1s 20ms/step - loss: 9.7284 - val_loss: 7.7643\n","Epoch 15/300\n","36/36 [==============================] - 1s 21ms/step - loss: 9.1499 - val_loss: 7.2704\n","Epoch 16/300\n","36/36 [==============================] - 1s 21ms/step - loss: 8.8617 - val_loss: 10.6228\n","Epoch 17/300\n","36/36 [==============================] - 1s 20ms/step - loss: 11.9118 - val_loss: 9.3366\n","Epoch 18/300\n","36/36 [==============================] - 1s 22ms/step - loss: 10.0032 - val_loss: 6.3747\n","Epoch 19/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.9504 - val_loss: 7.5651\n","Epoch 20/300\n","36/36 [==============================] - 1s 21ms/step - loss: 7.3846 - val_loss: 5.1280\n","Epoch 21/300\n","36/36 [==============================] - 1s 20ms/step - loss: 5.9518 - val_loss: 4.8276\n","Epoch 22/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.6226 - val_loss: 9.4548\n","Epoch 23/300\n","36/36 [==============================] - 1s 20ms/step - loss: 6.6274 - val_loss: 11.1777\n","Epoch 24/300\n","36/36 [==============================] - 1s 20ms/step - loss: 8.4614 - val_loss: 5.5248\n","Epoch 25/300\n","36/36 [==============================] - 1s 20ms/step - loss: 7.2066 - val_loss: 4.7050\n","Epoch 26/300\n","36/36 [==============================] - 1s 21ms/step - loss: 10.3017 - val_loss: 9.0367\n","Epoch 27/300\n","36/36 [==============================] - 1s 21ms/step - loss: 9.2202 - val_loss: 8.3905\n","Epoch 28/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.3224 - val_loss: 4.7968\n","Epoch 29/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.1848 - val_loss: 6.2390\n","Epoch 30/300\n","36/36 [==============================] - 1s 20ms/step - loss: 7.2312 - val_loss: 3.9753\n","Epoch 31/300\n","36/36 [==============================] - 1s 22ms/step - loss: 6.7853 - val_loss: 5.8851\n","Epoch 32/300\n","36/36 [==============================] - 1s 22ms/step - loss: 6.4498 - val_loss: 9.1277\n","Epoch 33/300\n","36/36 [==============================] - 1s 22ms/step - loss: 7.7159 - val_loss: 3.3726\n","Epoch 34/300\n","36/36 [==============================] - 1s 21ms/step - loss: 5.2687 - val_loss: 4.3940\n","Epoch 35/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.1274 - val_loss: 4.4936\n","Epoch 36/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.9373 - val_loss: 3.3801\n","Epoch 37/300\n","36/36 [==============================] - 1s 21ms/step - loss: 7.0971 - val_loss: 8.7770\n","Epoch 38/300\n","36/36 [==============================] - 1s 21ms/step - loss: 10.8942 - val_loss: 8.1854\n","Epoch 39/300\n","36/36 [==============================] - 1s 21ms/step - loss: 7.5715 - val_loss: 13.4184\n","Epoch 40/300\n","36/36 [==============================] - 1s 21ms/step - loss: 11.1478 - val_loss: 11.3545\n","Epoch 41/300\n","36/36 [==============================] - 1s 21ms/step - loss: 9.7802 - val_loss: 5.4216\n","Epoch 42/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.0357 - val_loss: 4.9926\n","Epoch 43/300\n","36/36 [==============================] - 1s 20ms/step - loss: 6.6459 - val_loss: 3.8119\n","Epoch 44/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.9674 - val_loss: 2.8483\n","Epoch 45/300\n","36/36 [==============================] - 1s 21ms/step - loss: 5.1551 - val_loss: 2.7818\n","Epoch 46/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.2817 - val_loss: 5.5765\n","Epoch 47/300\n","36/36 [==============================] - 1s 20ms/step - loss: 6.8614 - val_loss: 9.9592\n","Epoch 48/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.0713 - val_loss: 4.6419\n","Epoch 49/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.7256 - val_loss: 2.4501\n","Epoch 50/300\n","36/36 [==============================] - 1s 21ms/step - loss: 7.5325 - val_loss: 5.3670\n","Epoch 51/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.2238 - val_loss: 2.8930\n","Epoch 52/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.0056 - val_loss: 6.0507\n","Epoch 53/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.0382 - val_loss: 2.3666\n","Epoch 54/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.8846 - val_loss: 3.2183\n","Epoch 55/300\n","36/36 [==============================] - 1s 20ms/step - loss: 4.1139 - val_loss: 2.8744\n","Epoch 56/300\n","36/36 [==============================] - 1s 20ms/step - loss: 3.2538 - val_loss: 2.4086\n","Epoch 57/300\n","36/36 [==============================] - 1s 21ms/step - loss: 7.0598 - val_loss: 4.4867\n","Epoch 58/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.2249 - val_loss: 2.2533\n","Epoch 59/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.3937 - val_loss: 2.7211\n","Epoch 60/300\n","36/36 [==============================] - 1s 21ms/step - loss: 7.5684 - val_loss: 6.8058\n","Epoch 61/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.9321 - val_loss: 9.3065\n","Epoch 62/300\n","36/36 [==============================] - 1s 20ms/step - loss: 4.7599 - val_loss: 2.7965\n","Epoch 63/300\n","36/36 [==============================] - 1s 20ms/step - loss: 3.1512 - val_loss: 2.1649\n","Epoch 64/300\n","36/36 [==============================] - 1s 20ms/step - loss: 5.7811 - val_loss: 9.0123\n","Epoch 65/300\n","36/36 [==============================] - 1s 20ms/step - loss: 6.2471 - val_loss: 3.5011\n","Epoch 66/300\n","36/36 [==============================] - 1s 20ms/step - loss: 5.6287 - val_loss: 2.6334\n","Epoch 67/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.1451 - val_loss: 2.1835\n","Epoch 68/300\n","36/36 [==============================] - 1s 21ms/step - loss: 7.5868 - val_loss: 12.9449\n","Epoch 69/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.3175 - val_loss: 3.5599\n","Epoch 70/300\n","36/36 [==============================] - 1s 20ms/step - loss: 3.9658 - val_loss: 2.4683\n","Epoch 71/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.2403 - val_loss: 3.9477\n","Epoch 72/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.4309 - val_loss: 5.4295\n","Epoch 73/300\n","36/36 [==============================] - 1s 20ms/step - loss: 5.7961 - val_loss: 8.1434\n","Epoch 74/300\n","36/36 [==============================] - 1s 20ms/step - loss: 4.9476 - val_loss: 6.0297\n","Epoch 75/300\n","36/36 [==============================] - 1s 21ms/step - loss: 5.1341 - val_loss: 6.6084\n","Epoch 76/300\n","36/36 [==============================] - 1s 20ms/step - loss: 6.1822 - val_loss: 7.2162\n","Epoch 77/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.9175 - val_loss: 2.2249\n","Epoch 78/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.4204 - val_loss: 5.1958\n","Epoch 79/300\n","36/36 [==============================] - 1s 22ms/step - loss: 5.0011 - val_loss: 3.3745\n","Epoch 80/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.8619 - val_loss: 2.2211\n","Epoch 81/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.1128 - val_loss: 3.4901\n","Epoch 82/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.7337 - val_loss: 5.0900\n","Epoch 83/300\n","36/36 [==============================] - 1s 21ms/step - loss: 5.3883 - val_loss: 6.0106\n","Epoch 84/300\n","36/36 [==============================] - 1s 20ms/step - loss: 4.3714 - val_loss: 2.3856\n","Epoch 85/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.2796 - val_loss: 2.6642\n","Epoch 86/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.5516 - val_loss: 5.9038\n","Epoch 87/300\n","36/36 [==============================] - 1s 22ms/step - loss: 7.6292 - val_loss: 14.1696\n","Epoch 88/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.1941 - val_loss: 3.0186\n","Epoch 89/300\n","36/36 [==============================] - 1s 22ms/step - loss: 4.6202 - val_loss: 2.5896\n","Epoch 90/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.1387 - val_loss: 2.0527\n","Epoch 91/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.1770 - val_loss: 2.5432\n","Epoch 92/300\n","36/36 [==============================] - 1s 20ms/step - loss: 4.4096 - val_loss: 9.1140\n","Epoch 93/300\n","36/36 [==============================] - 1s 21ms/step - loss: 9.0835 - val_loss: 2.4015\n","Epoch 94/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.9566 - val_loss: 3.3125\n","Epoch 95/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.7690 - val_loss: 15.9765\n","Epoch 96/300\n","36/36 [==============================] - 1s 20ms/step - loss: 5.7364 - val_loss: 3.8351\n","Epoch 97/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.5346 - val_loss: 3.2408\n","Epoch 98/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.8589 - val_loss: 1.9591\n","Epoch 99/300\n","36/36 [==============================] - 1s 22ms/step - loss: 3.1965 - val_loss: 2.5266\n","Epoch 100/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.7904 - val_loss: 2.2694\n","Epoch 101/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.9377 - val_loss: 2.0666\n","Epoch 102/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.9170 - val_loss: 1.9776\n","Epoch 103/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.0387 - val_loss: 3.4415\n","Epoch 104/300\n","36/36 [==============================] - 1s 20ms/step - loss: 5.3333 - val_loss: 11.3719\n","Epoch 105/300\n","36/36 [==============================] - 1s 21ms/step - loss: 7.3915 - val_loss: 3.8110\n","Epoch 106/300\n","36/36 [==============================] - 1s 20ms/step - loss: 4.4777 - val_loss: 2.9220\n","Epoch 107/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.3344 - val_loss: 3.6935\n","Epoch 108/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.0454 - val_loss: 2.2272\n","Epoch 109/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.4760 - val_loss: 5.4775\n","Epoch 110/300\n","36/36 [==============================] - 1s 21ms/step - loss: 5.3942 - val_loss: 2.3912\n","Epoch 111/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.1389 - val_loss: 2.2497\n","Epoch 112/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.8676 - val_loss: 1.8512\n","Epoch 113/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.7632 - val_loss: 3.2003\n","Epoch 114/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.0131 - val_loss: 11.2556\n","Epoch 115/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.6476 - val_loss: 1.8830\n","Epoch 116/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.1999 - val_loss: 7.9685\n","Epoch 117/300\n","36/36 [==============================] - 1s 21ms/step - loss: 5.0150 - val_loss: 2.0077\n","Epoch 118/300\n","36/36 [==============================] - 1s 21ms/step - loss: 5.3004 - val_loss: 1.9618\n","Epoch 119/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.6970 - val_loss: 2.7521\n","Epoch 120/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.6077 - val_loss: 1.7967\n","Epoch 121/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.7978 - val_loss: 11.0929\n","Epoch 122/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.9244 - val_loss: 2.6165\n","Epoch 123/300\n","36/36 [==============================] - 1s 20ms/step - loss: 2.6703 - val_loss: 4.8499\n","Epoch 124/300\n","36/36 [==============================] - 1s 21ms/step - loss: 5.5650 - val_loss: 2.7104\n","Epoch 125/300\n","36/36 [==============================] - 1s 21ms/step - loss: 7.3982 - val_loss: 4.8171\n","Epoch 126/300\n","36/36 [==============================] - 1s 21ms/step - loss: 5.0612 - val_loss: 1.8378\n","Epoch 127/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.2852 - val_loss: 7.6051\n","Epoch 128/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.6872 - val_loss: 4.4779\n","Epoch 129/300\n","36/36 [==============================] - 1s 21ms/step - loss: 5.4276 - val_loss: 5.9149\n","Epoch 130/300\n","36/36 [==============================] - 1s 22ms/step - loss: 4.5923 - val_loss: 8.4049\n","Epoch 131/300\n","36/36 [==============================] - 1s 22ms/step - loss: 3.2791 - val_loss: 1.7616\n","Epoch 132/300\n","36/36 [==============================] - 1s 21ms/step - loss: 5.3696 - val_loss: 5.4498\n","Epoch 133/300\n","36/36 [==============================] - 1s 20ms/step - loss: 5.1121 - val_loss: 10.8026\n","Epoch 134/300\n","36/36 [==============================] - 1s 21ms/step - loss: 5.1718 - val_loss: 4.8918\n","Epoch 135/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.3013 - val_loss: 3.9000\n","Epoch 136/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.4241 - val_loss: 2.0332\n","Epoch 137/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.4922 - val_loss: 2.1438\n","Epoch 138/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.2826 - val_loss: 2.0014\n","Epoch 139/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.5117 - val_loss: 1.7667\n","Epoch 140/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.0588 - val_loss: 3.1278\n","Epoch 141/300\n","36/36 [==============================] - 1s 23ms/step - loss: 5.4399 - val_loss: 10.9477\n","Epoch 142/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.9735 - val_loss: 2.7401\n","Epoch 143/300\n","36/36 [==============================] - 1s 21ms/step - loss: 5.2456 - val_loss: 3.5491\n","Epoch 144/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.9634 - val_loss: 4.0735\n","Epoch 145/300\n","36/36 [==============================] - 1s 22ms/step - loss: 6.2546 - val_loss: 3.9635\n","Epoch 146/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.6425 - val_loss: 1.8653\n","Epoch 147/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.8457 - val_loss: 6.3880\n","Epoch 148/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.3427 - val_loss: 2.4286\n","Epoch 149/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.4196 - val_loss: 1.8382\n","Epoch 150/300\n","36/36 [==============================] - 1s 22ms/step - loss: 3.5867 - val_loss: 1.8976\n","Epoch 151/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.0488 - val_loss: 1.9407\n","Epoch 152/300\n","36/36 [==============================] - 1s 22ms/step - loss: 3.5715 - val_loss: 7.1594\n","Epoch 153/300\n","36/36 [==============================] - 1s 24ms/step - loss: 5.8094 - val_loss: 10.5736\n","Epoch 154/300\n","36/36 [==============================] - 1s 23ms/step - loss: 6.9090 - val_loss: 12.7141\n","Epoch 155/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.1631 - val_loss: 11.3851\n","Epoch 156/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.8348 - val_loss: 1.6833\n","Epoch 157/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.9122 - val_loss: 3.0564\n","Epoch 158/300\n","36/36 [==============================] - 1s 21ms/step - loss: 5.7632 - val_loss: 6.9145\n","Epoch 159/300\n","36/36 [==============================] - 1s 21ms/step - loss: 7.1995 - val_loss: 7.3466\n","Epoch 160/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.2232 - val_loss: 3.4087\n","Epoch 161/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.3666 - val_loss: 1.8150\n","Epoch 162/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.8590 - val_loss: 4.2897\n","Epoch 163/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.3289 - val_loss: 4.2930\n","Epoch 164/300\n","36/36 [==============================] - 1s 22ms/step - loss: 4.4264 - val_loss: 1.8477\n","Epoch 165/300\n","36/36 [==============================] - 1s 22ms/step - loss: 2.3976 - val_loss: 1.7409\n","Epoch 166/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.3917 - val_loss: 4.6106\n","Epoch 167/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.3922 - val_loss: 2.3328\n","Epoch 168/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.3850 - val_loss: 7.6356\n","Epoch 169/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.7718 - val_loss: 3.6893\n","Epoch 170/300\n","36/36 [==============================] - 1s 21ms/step - loss: 5.1372 - val_loss: 3.2440\n","Epoch 171/300\n","36/36 [==============================] - 1s 21ms/step - loss: 5.6130 - val_loss: 2.4558\n","Epoch 172/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.1490 - val_loss: 6.3865\n","Epoch 173/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.8415 - val_loss: 2.4261\n","Epoch 174/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.1394 - val_loss: 7.4668\n","Epoch 175/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.3519 - val_loss: 2.6369\n","Epoch 176/300\n","36/36 [==============================] - 1s 21ms/step - loss: 5.8316 - val_loss: 4.1491\n","Epoch 177/300\n","36/36 [==============================] - 1s 22ms/step - loss: 5.4958 - val_loss: 10.5496\n","Epoch 178/300\n","36/36 [==============================] - 1s 21ms/step - loss: 5.0228 - val_loss: 5.5423\n","Epoch 179/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.7393 - val_loss: 1.9341\n","Epoch 180/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.0703 - val_loss: 4.3654\n","Epoch 181/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.6310 - val_loss: 1.6861\n","Epoch 182/300\n","36/36 [==============================] - 1s 20ms/step - loss: 2.6951 - val_loss: 2.8384\n","Epoch 183/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.4528 - val_loss: 2.8490\n","Epoch 184/300\n","36/36 [==============================] - 1s 22ms/step - loss: 2.7384 - val_loss: 1.7147\n","Epoch 185/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.6423 - val_loss: 3.2764\n","Epoch 186/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.7030 - val_loss: 2.0787\n","Epoch 187/300\n","36/36 [==============================] - 1s 22ms/step - loss: 3.1034 - val_loss: 5.5366\n","Epoch 188/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.9281 - val_loss: 5.1630\n","Epoch 189/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.2822 - val_loss: 1.7199\n","Epoch 190/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.8229 - val_loss: 7.8329\n","Epoch 191/300\n","36/36 [==============================] - 1s 22ms/step - loss: 7.4832 - val_loss: 10.6453\n","Epoch 192/300\n","36/36 [==============================] - 1s 22ms/step - loss: 4.8981 - val_loss: 6.7964\n","Epoch 193/300\n","36/36 [==============================] - 1s 20ms/step - loss: 5.5258 - val_loss: 6.6940\n","Epoch 194/300\n","36/36 [==============================] - 1s 20ms/step - loss: 3.1818 - val_loss: 1.8926\n","Epoch 195/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.9361 - val_loss: 3.0686\n","Epoch 196/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.1150 - val_loss: 6.3012\n","Epoch 197/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.4397 - val_loss: 1.7172\n","Epoch 198/300\n","36/36 [==============================] - 1s 20ms/step - loss: 3.7870 - val_loss: 1.8942\n","Epoch 199/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.8205 - val_loss: 4.8606\n","Epoch 200/300\n","36/36 [==============================] - 1s 21ms/step - loss: 5.9201 - val_loss: 6.2451\n","Epoch 201/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.5028 - val_loss: 5.6013\n","Epoch 202/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.7901 - val_loss: 6.5855\n","Epoch 203/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.7931 - val_loss: 2.7202\n","Epoch 204/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.2183 - val_loss: 2.7197\n","Epoch 205/300\n","36/36 [==============================] - 1s 22ms/step - loss: 2.8966 - val_loss: 1.7537\n","Epoch 206/300\n","36/36 [==============================] - 1s 20ms/step - loss: 2.1768 - val_loss: 3.4580\n","Epoch 207/300\n","36/36 [==============================] - 1s 21ms/step - loss: 5.6357 - val_loss: 1.6735\n","Epoch 208/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.1844 - val_loss: 2.4006\n","Epoch 209/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.1431 - val_loss: 3.9614\n","Epoch 210/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.9511 - val_loss: 1.5158\n","Epoch 211/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.7910 - val_loss: 3.6288\n","Epoch 212/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.9280 - val_loss: 2.4801\n","Epoch 213/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.2054 - val_loss: 13.1268\n","Epoch 214/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.8233 - val_loss: 5.9613\n","Epoch 215/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.8611 - val_loss: 2.1185\n","Epoch 216/300\n","36/36 [==============================] - 1s 22ms/step - loss: 3.6796 - val_loss: 2.3441\n","Epoch 217/300\n","36/36 [==============================] - 1s 22ms/step - loss: 4.7204 - val_loss: 5.9647\n","Epoch 218/300\n","36/36 [==============================] - 1s 22ms/step - loss: 3.4222 - val_loss: 4.6704\n","Epoch 219/300\n","36/36 [==============================] - 1s 22ms/step - loss: 2.7505 - val_loss: 2.4403\n","Epoch 220/300\n","36/36 [==============================] - 1s 22ms/step - loss: 3.3206 - val_loss: 4.1572\n","Epoch 221/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.5958 - val_loss: 8.4097\n","Epoch 222/300\n","36/36 [==============================] - 1s 22ms/step - loss: 4.3161 - val_loss: 2.6133\n","Epoch 223/300\n","36/36 [==============================] - 1s 22ms/step - loss: 6.0257 - val_loss: 4.0104\n","Epoch 224/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.7143 - val_loss: 1.4041\n","Epoch 225/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.0245 - val_loss: 1.4312\n","Epoch 226/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.2101 - val_loss: 1.4340\n","Epoch 227/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.6967 - val_loss: 14.7433\n","Epoch 228/300\n","36/36 [==============================] - 1s 23ms/step - loss: 8.5507 - val_loss: 2.5243\n","Epoch 229/300\n","36/36 [==============================] - 1s 21ms/step - loss: 6.0088 - val_loss: 1.5512\n","Epoch 230/300\n","36/36 [==============================] - 1s 22ms/step - loss: 5.8465 - val_loss: 5.9594\n","Epoch 231/300\n","36/36 [==============================] - 1s 23ms/step - loss: 5.3022 - val_loss: 1.6320\n","Epoch 232/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.0383 - val_loss: 2.0800\n","Epoch 233/300\n","36/36 [==============================] - 1s 22ms/step - loss: 5.5590 - val_loss: 3.3246\n","Epoch 234/300\n","36/36 [==============================] - 1s 22ms/step - loss: 2.4844 - val_loss: 2.4689\n","Epoch 235/300\n","36/36 [==============================] - 1s 22ms/step - loss: 2.1502 - val_loss: 1.6652\n","Epoch 236/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.7144 - val_loss: 2.0701\n","Epoch 237/300\n","36/36 [==============================] - 1s 21ms/step - loss: 5.1393 - val_loss: 5.9530\n","Epoch 238/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.7501 - val_loss: 3.2112\n","Epoch 239/300\n","36/36 [==============================] - 1s 21ms/step - loss: 5.3523 - val_loss: 1.5440\n","Epoch 240/300\n","36/36 [==============================] - 1s 22ms/step - loss: 5.4876 - val_loss: 1.6141\n","Epoch 241/300\n","36/36 [==============================] - 1s 22ms/step - loss: 3.0253 - val_loss: 1.3752\n","Epoch 242/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.5924 - val_loss: 1.9927\n","Epoch 243/300\n","36/36 [==============================] - 1s 22ms/step - loss: 5.0605 - val_loss: 11.0881\n","Epoch 244/300\n","36/36 [==============================] - 1s 22ms/step - loss: 4.3471 - val_loss: 1.5254\n","Epoch 245/300\n","36/36 [==============================] - 1s 22ms/step - loss: 3.9472 - val_loss: 10.3117\n","Epoch 246/300\n","36/36 [==============================] - 1s 23ms/step - loss: 3.9302 - val_loss: 5.1080\n","Epoch 247/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.3861 - val_loss: 7.3655\n","Epoch 248/300\n","36/36 [==============================] - 1s 22ms/step - loss: 4.6610 - val_loss: 3.6458\n","Epoch 249/300\n","36/36 [==============================] - 1s 22ms/step - loss: 2.5726 - val_loss: 2.0224\n","Epoch 250/300\n","36/36 [==============================] - 1s 22ms/step - loss: 2.2400 - val_loss: 3.3681\n","Epoch 251/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.1878 - val_loss: 5.1844\n","Epoch 252/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.4322 - val_loss: 1.5623\n","Epoch 253/300\n","36/36 [==============================] - 1s 22ms/step - loss: 3.3432 - val_loss: 1.5513\n","Epoch 254/300\n","36/36 [==============================] - 1s 22ms/step - loss: 4.0573 - val_loss: 5.8430\n","Epoch 255/300\n","36/36 [==============================] - 1s 22ms/step - loss: 6.3545 - val_loss: 6.1039\n","Epoch 256/300\n","36/36 [==============================] - 1s 21ms/step - loss: 5.0574 - val_loss: 1.7019\n","Epoch 257/300\n","36/36 [==============================] - 1s 22ms/step - loss: 4.0210 - val_loss: 3.9209\n","Epoch 258/300\n","36/36 [==============================] - 1s 20ms/step - loss: 3.2463 - val_loss: 1.4446\n","Epoch 259/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.7804 - val_loss: 4.6355\n","Epoch 260/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.6749 - val_loss: 1.4243\n","Epoch 261/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.6389 - val_loss: 5.9748\n","Epoch 262/300\n","36/36 [==============================] - 1s 22ms/step - loss: 4.6627 - val_loss: 1.4402\n","Epoch 263/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.3280 - val_loss: 1.9486\n","Epoch 264/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.2623 - val_loss: 1.6215\n","Epoch 265/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.9406 - val_loss: 3.7426\n","Epoch 266/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.5171 - val_loss: 1.8456\n","Epoch 267/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.6884 - val_loss: 2.4417\n","Epoch 268/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.0465 - val_loss: 2.0244\n","Epoch 269/300\n","36/36 [==============================] - 1s 22ms/step - loss: 2.0953 - val_loss: 2.4668\n","Epoch 270/300\n","36/36 [==============================] - 1s 23ms/step - loss: 2.1621 - val_loss: 1.4924\n","Epoch 271/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.5022 - val_loss: 1.7175\n","Epoch 272/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.7944 - val_loss: 5.1967\n","Epoch 273/300\n","36/36 [==============================] - 1s 21ms/step - loss: 5.4245 - val_loss: 2.5002\n","Epoch 274/300\n","36/36 [==============================] - 1s 22ms/step - loss: 4.5094 - val_loss: 1.3088\n","Epoch 275/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.0707 - val_loss: 4.1505\n","Epoch 276/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.0591 - val_loss: 6.8966\n","Epoch 277/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.9174 - val_loss: 4.6923\n","Epoch 278/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.5015 - val_loss: 1.3834\n","Epoch 279/300\n","36/36 [==============================] - 1s 20ms/step - loss: 3.4789 - val_loss: 3.4340\n","Epoch 280/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.1630 - val_loss: 1.7734\n","Epoch 281/300\n","36/36 [==============================] - 1s 21ms/step - loss: 7.1643 - val_loss: 12.6152\n","Epoch 282/300\n","36/36 [==============================] - 1s 21ms/step - loss: 5.4964 - val_loss: 2.5123\n","Epoch 283/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.0505 - val_loss: 3.4277\n","Epoch 284/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.2449 - val_loss: 1.9400\n","Epoch 285/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.7564 - val_loss: 3.2255\n","Epoch 286/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.1878 - val_loss: 1.5158\n","Epoch 287/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.7616 - val_loss: 4.6165\n","Epoch 288/300\n","36/36 [==============================] - 1s 21ms/step - loss: 4.4777 - val_loss: 6.2684\n","Epoch 289/300\n","36/36 [==============================] - 1s 22ms/step - loss: 3.8534 - val_loss: 1.7714\n","Epoch 290/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.8019 - val_loss: 1.7616\n","Epoch 291/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.4891 - val_loss: 1.7637\n","Epoch 292/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.1908 - val_loss: 3.5575\n","Epoch 293/300\n","36/36 [==============================] - 1s 22ms/step - loss: 3.5965 - val_loss: 1.9753\n","Epoch 294/300\n","36/36 [==============================] - 1s 21ms/step - loss: 2.3153 - val_loss: 1.2830\n","Epoch 295/300\n","36/36 [==============================] - 1s 21ms/step - loss: 5.1527 - val_loss: 1.7153\n","Epoch 296/300\n","36/36 [==============================] - 1s 22ms/step - loss: 1.9159 - val_loss: 2.0900\n","Epoch 297/300\n","36/36 [==============================] - 1s 22ms/step - loss: 3.0114 - val_loss: 5.4000\n","Epoch 298/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.3987 - val_loss: 1.4387\n","Epoch 299/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.6633 - val_loss: 2.6286\n","Epoch 300/300\n","36/36 [==============================] - 1s 21ms/step - loss: 3.7295 - val_loss: 3.6348\n"]}]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":151313,"status":"ok","timestamp":1639323971644,"user":{"displayName":"Shamima Akter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPJvbs09XMJHGonY2iTwD9S7s6hYvWVwxn5XfX=s64","userId":"07570024981421945247"},"user_tz":300},"id":"onaIxLHGNPGq","outputId":"b979c349-022f-4853-d351-4da73687a9f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","142/142 [==============================] - 3s 12ms/step - loss: 3643.7917 - val_loss: 650.0334\n","Epoch 2/100\n","142/142 [==============================] - 2s 11ms/step - loss: 700.7782 - val_loss: 681.8185\n","Epoch 3/100\n","142/142 [==============================] - 1s 10ms/step - loss: 651.4965 - val_loss: 563.2095\n","Epoch 4/100\n","142/142 [==============================] - 2s 11ms/step - loss: 600.3655 - val_loss: 628.1754\n","Epoch 5/100\n","142/142 [==============================] - 1s 10ms/step - loss: 520.7903 - val_loss: 427.8200\n","Epoch 6/100\n","142/142 [==============================] - 1s 11ms/step - loss: 438.9160 - val_loss: 333.6065\n","Epoch 7/100\n","142/142 [==============================] - 2s 11ms/step - loss: 337.5905 - val_loss: 317.6798\n","Epoch 8/100\n","142/142 [==============================] - 2s 11ms/step - loss: 219.8854 - val_loss: 115.5380\n","Epoch 9/100\n","142/142 [==============================] - 2s 11ms/step - loss: 91.9207 - val_loss: 56.1680\n","Epoch 10/100\n","142/142 [==============================] - 1s 10ms/step - loss: 57.2566 - val_loss: 26.5366\n","Epoch 11/100\n","142/142 [==============================] - 1s 10ms/step - loss: 49.7110 - val_loss: 23.4718\n","Epoch 12/100\n","142/142 [==============================] - 2s 11ms/step - loss: 43.3175 - val_loss: 20.2492\n","Epoch 13/100\n","142/142 [==============================] - 1s 10ms/step - loss: 43.5797 - val_loss: 22.9507\n","Epoch 14/100\n","142/142 [==============================] - 1s 10ms/step - loss: 44.1356 - val_loss: 18.1224\n","Epoch 15/100\n","142/142 [==============================] - 1s 10ms/step - loss: 36.5274 - val_loss: 19.5512\n","Epoch 16/100\n","142/142 [==============================] - 1s 10ms/step - loss: 34.2968 - val_loss: 13.9707\n","Epoch 17/100\n","142/142 [==============================] - 1s 10ms/step - loss: 34.4910 - val_loss: 14.7902\n","Epoch 18/100\n","142/142 [==============================] - 2s 11ms/step - loss: 29.4648 - val_loss: 15.8781\n","Epoch 19/100\n","142/142 [==============================] - 2s 11ms/step - loss: 24.0930 - val_loss: 90.6805\n","Epoch 20/100\n","142/142 [==============================] - 1s 10ms/step - loss: 41.1743 - val_loss: 11.6519\n","Epoch 21/100\n","142/142 [==============================] - 1s 10ms/step - loss: 32.7844 - val_loss: 13.4235\n","Epoch 22/100\n","142/142 [==============================] - 1s 10ms/step - loss: 38.9949 - val_loss: 59.5000\n","Epoch 23/100\n","142/142 [==============================] - 1s 10ms/step - loss: 26.7263 - val_loss: 27.9478\n","Epoch 24/100\n","142/142 [==============================] - 1s 10ms/step - loss: 22.5333 - val_loss: 11.8255\n","Epoch 25/100\n","142/142 [==============================] - 1s 10ms/step - loss: 25.3473 - val_loss: 11.0969\n","Epoch 26/100\n","142/142 [==============================] - 1s 10ms/step - loss: 19.8571 - val_loss: 10.4209\n","Epoch 27/100\n","142/142 [==============================] - 1s 10ms/step - loss: 24.1145 - val_loss: 15.4861\n","Epoch 28/100\n","142/142 [==============================] - 1s 10ms/step - loss: 24.2698 - val_loss: 10.6326\n","Epoch 29/100\n","142/142 [==============================] - 1s 10ms/step - loss: 16.6618 - val_loss: 15.3542\n","Epoch 30/100\n","142/142 [==============================] - 1s 10ms/step - loss: 17.2780 - val_loss: 17.3824\n","Epoch 31/100\n","142/142 [==============================] - 2s 11ms/step - loss: 21.2317 - val_loss: 29.9736\n","Epoch 32/100\n","142/142 [==============================] - 1s 10ms/step - loss: 112.5994 - val_loss: 9.4792\n","Epoch 33/100\n","142/142 [==============================] - 1s 10ms/step - loss: 16.0070 - val_loss: 9.4885\n","Epoch 34/100\n","142/142 [==============================] - 1s 10ms/step - loss: 16.1384 - val_loss: 9.3388\n","Epoch 35/100\n","142/142 [==============================] - 1s 10ms/step - loss: 14.2743 - val_loss: 15.8107\n","Epoch 36/100\n","142/142 [==============================] - 1s 10ms/step - loss: 26.2630 - val_loss: 24.6893\n","Epoch 37/100\n","142/142 [==============================] - 1s 10ms/step - loss: 24.4225 - val_loss: 31.3865\n","Epoch 38/100\n","142/142 [==============================] - 1s 10ms/step - loss: 22.7080 - val_loss: 19.3300\n","Epoch 39/100\n","142/142 [==============================] - 2s 11ms/step - loss: 17.8964 - val_loss: 15.5881\n","Epoch 40/100\n","142/142 [==============================] - 1s 10ms/step - loss: 14.5946 - val_loss: 12.0545\n","Epoch 41/100\n","142/142 [==============================] - 1s 10ms/step - loss: 12.4884 - val_loss: 10.3660\n","Epoch 42/100\n","142/142 [==============================] - 1s 10ms/step - loss: 15.1579 - val_loss: 19.5952\n","Epoch 43/100\n","142/142 [==============================] - 1s 10ms/step - loss: 24.9402 - val_loss: 8.8149\n","Epoch 44/100\n","142/142 [==============================] - 1s 10ms/step - loss: 23.5305 - val_loss: 10.7824\n","Epoch 45/100\n","142/142 [==============================] - 1s 10ms/step - loss: 21.9492 - val_loss: 11.4113\n","Epoch 46/100\n","142/142 [==============================] - 1s 10ms/step - loss: 23.1666 - val_loss: 168.0085\n","Epoch 47/100\n","142/142 [==============================] - 1s 10ms/step - loss: 33.5909 - val_loss: 11.1473\n","Epoch 48/100\n","142/142 [==============================] - 1s 10ms/step - loss: 36.0849 - val_loss: 10.4006\n","Epoch 49/100\n","142/142 [==============================] - 1s 10ms/step - loss: 13.3161 - val_loss: 9.1267\n","Epoch 50/100\n","142/142 [==============================] - 1s 10ms/step - loss: 10.8466 - val_loss: 17.4801\n","Epoch 51/100\n","142/142 [==============================] - 1s 10ms/step - loss: 13.4728 - val_loss: 10.2984\n","Epoch 52/100\n","142/142 [==============================] - 1s 10ms/step - loss: 21.0744 - val_loss: 30.1272\n","Epoch 53/100\n","142/142 [==============================] - 2s 11ms/step - loss: 14.0472 - val_loss: 15.3275\n","Epoch 54/100\n","142/142 [==============================] - 2s 11ms/step - loss: 14.5661 - val_loss: 9.1015\n","Epoch 55/100\n","142/142 [==============================] - 1s 10ms/step - loss: 9.2654 - val_loss: 10.6807\n","Epoch 56/100\n","142/142 [==============================] - 1s 10ms/step - loss: 22.7138 - val_loss: 20.3285\n","Epoch 57/100\n","142/142 [==============================] - 1s 10ms/step - loss: 13.9758 - val_loss: 6.9610\n","Epoch 58/100\n","142/142 [==============================] - 1s 10ms/step - loss: 19.4388 - val_loss: 6.8152\n","Epoch 59/100\n","142/142 [==============================] - 2s 11ms/step - loss: 15.3878 - val_loss: 11.1699\n","Epoch 60/100\n","142/142 [==============================] - 1s 10ms/step - loss: 11.6445 - val_loss: 5.2726\n","Epoch 61/100\n","142/142 [==============================] - 1s 10ms/step - loss: 17.6157 - val_loss: 7.8190\n","Epoch 62/100\n","142/142 [==============================] - 1s 10ms/step - loss: 18.9153 - val_loss: 15.6181\n","Epoch 63/100\n","142/142 [==============================] - 1s 10ms/step - loss: 10.7788 - val_loss: 5.7149\n","Epoch 64/100\n","142/142 [==============================] - 2s 11ms/step - loss: 10.5080 - val_loss: 7.4020\n","Epoch 65/100\n","142/142 [==============================] - 1s 11ms/step - loss: 13.2419 - val_loss: 6.3925\n","Epoch 66/100\n","142/142 [==============================] - 2s 11ms/step - loss: 10.3088 - val_loss: 41.1418\n","Epoch 67/100\n","142/142 [==============================] - 1s 10ms/step - loss: 11.1245 - val_loss: 7.7470\n","Epoch 68/100\n","142/142 [==============================] - 1s 10ms/step - loss: 11.0429 - val_loss: 11.5367\n","Epoch 69/100\n","142/142 [==============================] - 1s 10ms/step - loss: 17.5790 - val_loss: 9.2263\n","Epoch 70/100\n","142/142 [==============================] - 2s 11ms/step - loss: 11.0429 - val_loss: 7.6311\n","Epoch 71/100\n","142/142 [==============================] - 1s 10ms/step - loss: 18.3757 - val_loss: 32.1398\n","Epoch 72/100\n","142/142 [==============================] - 2s 11ms/step - loss: 16.0348 - val_loss: 5.9429\n","Epoch 73/100\n","142/142 [==============================] - 1s 10ms/step - loss: 22.2494 - val_loss: 28.1842\n","Epoch 74/100\n","142/142 [==============================] - 1s 11ms/step - loss: 10.3328 - val_loss: 6.4493\n","Epoch 75/100\n","142/142 [==============================] - 1s 10ms/step - loss: 13.4320 - val_loss: 9.8165\n","Epoch 76/100\n","142/142 [==============================] - 1s 10ms/step - loss: 12.7391 - val_loss: 10.4343\n","Epoch 77/100\n","142/142 [==============================] - 1s 10ms/step - loss: 9.2119 - val_loss: 7.2774\n","Epoch 78/100\n","142/142 [==============================] - 2s 11ms/step - loss: 13.7101 - val_loss: 22.8006\n","Epoch 79/100\n","142/142 [==============================] - 2s 11ms/step - loss: 8.2784 - val_loss: 4.4598\n","Epoch 80/100\n","142/142 [==============================] - 1s 11ms/step - loss: 10.4832 - val_loss: 8.0125\n","Epoch 81/100\n","142/142 [==============================] - 1s 10ms/step - loss: 15.9583 - val_loss: 17.2419\n","Epoch 82/100\n","142/142 [==============================] - 1s 10ms/step - loss: 26.6729 - val_loss: 5.9411\n","Epoch 83/100\n","142/142 [==============================] - 1s 10ms/step - loss: 10.0484 - val_loss: 6.0642\n","Epoch 84/100\n","142/142 [==============================] - 2s 11ms/step - loss: 10.2146 - val_loss: 18.1334\n","Epoch 85/100\n","142/142 [==============================] - 2s 11ms/step - loss: 6.9869 - val_loss: 20.2951\n","Epoch 86/100\n","142/142 [==============================] - 1s 11ms/step - loss: 9.7205 - val_loss: 3.9753\n","Epoch 87/100\n","142/142 [==============================] - 2s 11ms/step - loss: 9.8407 - val_loss: 8.4172\n","Epoch 88/100\n","142/142 [==============================] - 2s 11ms/step - loss: 8.5822 - val_loss: 4.9969\n","Epoch 89/100\n","142/142 [==============================] - 2s 11ms/step - loss: 16.0950 - val_loss: 4.5773\n","Epoch 90/100\n","142/142 [==============================] - 1s 11ms/step - loss: 11.4360 - val_loss: 10.6468\n","Epoch 91/100\n","142/142 [==============================] - 2s 11ms/step - loss: 15.1240 - val_loss: 5.2758\n","Epoch 92/100\n","142/142 [==============================] - 2s 11ms/step - loss: 15.5023 - val_loss: 13.5968\n","Epoch 93/100\n","142/142 [==============================] - 1s 10ms/step - loss: 16.4210 - val_loss: 6.1242\n","Epoch 94/100\n","142/142 [==============================] - 2s 11ms/step - loss: 6.6542 - val_loss: 15.2190\n","Epoch 95/100\n","142/142 [==============================] - 2s 11ms/step - loss: 11.2005 - val_loss: 3.3605\n","Epoch 96/100\n","142/142 [==============================] - 2s 11ms/step - loss: 10.7151 - val_loss: 8.3462\n","Epoch 97/100\n","142/142 [==============================] - 1s 10ms/step - loss: 6.8708 - val_loss: 4.8169\n","Epoch 98/100\n","142/142 [==============================] - 2s 11ms/step - loss: 9.9417 - val_loss: 19.1934\n","Epoch 99/100\n","142/142 [==============================] - 2s 11ms/step - loss: 8.1777 - val_loss: 3.8089\n","Epoch 100/100\n","142/142 [==============================] - 2s 11ms/step - loss: 11.7184 - val_loss: 5.0138\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f9126dead10>"]},"metadata":{},"execution_count":17}],"source":["model = Sequential()\n","#model.add(LSTM(64,return_sequences=True, input_shape=(X_train.shape[1],1)))\n","model.add(LSTM(64,activation='relu', input_shape=(X_train.shape[1],1)))\n","#model.add(Dropout(0.5))\n","#model.add(LSTM(20,return_sequences=False))\n","#model.add(Dropout(0.5))\n","model.add(Dense(1))\n","model.compile(loss='mse', optimizer='adam')\n","model.fit(X_train,y_train,epochs=100,validation_data=(X_test, y_test))"]},{"cell_type":"code","source":[""],"metadata":{"id":"TmgFHyQGAc7E"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":37,"metadata":{"id":"K5MwDJKOsDhi","executionInfo":{"status":"ok","timestamp":1639325457416,"user_tz":300,"elapsed":439,"user":{"displayName":"Shamima Akter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPJvbs09XMJHGonY2iTwD9S7s6hYvWVwxn5XfX=s64","userId":"07570024981421945247"}}},"outputs":[],"source":["y_predict = model.predict(X_test)"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"BG-J7eCGsHZh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639325463358,"user_tz":300,"elapsed":145,"user":{"displayName":"Shamima Akter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPJvbs09XMJHGonY2iTwD9S7s6hYvWVwxn5XfX=s64","userId":"07570024981421945247"}},"outputId":"b7da1d0c-53e8-4a39-c9d6-7ce77c6c9182"},"outputs":[{"output_type":"stream","name":"stdout","text":["MAE:  2.068031618778198\n","MAPE:  206.8031618778198\n","MSE:  12.168075216941608\n","RMSE:  3.4882768263057344\n","RMAE:  1.4380652345349978\n","R2:  0.9980500299105809\n"]}],"source":["from sklearn import metrics\n","print('MAE: ', metrics.mean_absolute_error(y_test, y_predict))\n","print('MAPE: ', metrics.mean_absolute_error(y_test, y_predict)*100)\n","print('MSE: ', metrics.mean_squared_error(y_test, y_predict))\n","print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, y_predict)))\n","print('RMAE: ', np.sqrt(metrics.mean_absolute_error(y_test, y_predict)))\n","print('R2: ', metrics.r2_score(y_test, y_predict))"]},{"cell_type":"code","source":["model = Sequential()\n","#Adding the first LSTM layer and some Dropout regularisation\n","model.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n","model.add(Dropout(0.2))\n","# Adding a second LSTM layer and some Dropout regularisation\n","model.add(LSTM(units = 50, return_sequences = True))\n","model.add(Dropout(0.2))\n","# Adding a third LSTM layer and some Dropout regularisation\n","model.add(LSTM(units = 50, return_sequences = False))\n","model.add(Dropout(0.2))\n","# Adding a fourth LSTM layer and some Dropout regularisation\n","model.add(LSTM(units = 50))\n","model.add(Dropout(0.2))\n","# Adding the output layer\n","model.add(Dense(units = 1))\n","\n","# Compiling the RNN\n","model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n","\n","# Fitting the RNN to the Training set\n","model.fit(X_train, y_train, epochs = 100, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"ppdq3lWI-jkM","executionInfo":{"status":"error","timestamp":1639318387067,"user_tz":300,"elapsed":952,"user":{"displayName":"Manik Ahmed","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11247937406887651800"}},"outputId":"9e6c3ffb-3a3a-4d16-e661-dfc52dcc2202"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-07f1cf0b61c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Adding a fourth LSTM layer and some Dropout regularisation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Adding the output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    211\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\u001b[0m\u001b[1;32m    214\u001b[0m                          \u001b[0;34m'is incompatible with the layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                          \u001b[0;34mf'expected ndim={spec.ndim}, found ndim={ndim}. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"lstm_17\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 50)"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"Pcv5Wm3V-w7D"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1pfiAwE1NbF9","colab":{"base_uri":"https://localhost:8080/","height":252},"executionInfo":{"status":"error","timestamp":1639317913178,"user_tz":300,"elapsed":608,"user":{"displayName":"Manik Ahmed","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11247937406887651800"}},"outputId":"82183912-d264-47af-988a-e455c27ed7c8"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-d13647e62667>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{}}],"source":["import matplotlib.pyplot as plt\n","\n","fig = plt.gcf()\n","plt.plot(history.history['loss']) \n","plt.plot(history.history['val_loss'])\n","plt.title('LSTM')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend(['loss', 'validation loss'], loc='upper right')\n","plt.show()\n","fig.savefig('LSTM.png', dpi=100)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BDfnEc3WeGuM"},"outputs":[],"source":["y_predict = model.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QO_gs_7HeFOI"},"outputs":[],"source":["from sklearn import metrics\n","print('MAE: ', metrics.mean_absolute_error(y_test, y_predict))\n","print('MAPE: ', metrics.mean_absolute_error(y_test, y_predict)*100)\n","print('MSE: ', metrics.mean_squared_error(y_test, y_predict))\n","print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, y_predict)))\n","print('RMAE: ', np.sqrt(metrics.mean_absolute_error(y_test, y_predict)))\n","print('R2: ', metrics.r2_score(y_test, y_predict))"]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":[],"name":"LSTM_new.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}